---
import Base from "@layouts/Base.astro";
import Nav from "@components/Nav.astro";
import "@styles/global.css";

const base = import.meta.env.BASE_URL;
---

<Base title="About -- EngramR" description="The vision behind EngramR: why research labs need cumulative knowledge infrastructure.">
  <Nav />
  <div class="max-w-3xl mx-auto px-6 pt-20 pb-16">
    <article class="doc-prose">
      <h1>Engram Reactor</h1>

      <h2 id="the-problem">The problem is not ideas. It is visibility.</h2>

      <p>
        Every lab meeting, we discuss many promising directions. How do we decide which
        ones to pursue, and based on what evidence? Without a system to track and compare
        them, the evidence sits fragmented -- so no one can reliably see the full picture.
      </p>
      <p>
        When I joined the lab, it took me three weeks just to understand what each team
        member was working on and where the group was heading. That context lived in
        people's heads -- in scattered conversations, slides, in the PI's intuition.
        There was no single place to look. A postdoc reads a paper that contradicts an
        assumption but files it under "interesting" and moves on. A technician notices
        something unexpected but has no time to chase it down. These insights are real,
        but without a system to persist them, they fade.
      </p>
      <p>
        The ideas that do surface face a harder problem: our lab has finite bench hours,
        finite instrument budget, finite analyst bandwidth. Ten good ideas compete for
        three experimental slots. The ones that get pursued are not always the ones best
        supported by evidence -- they are the ones someone had time to champion.
      </p>
      <p>
        <strong>The gap is not analytical skill or scientific creativity. It is the
        infrastructure to accumulate evidence and convert it into prioritized action.</strong>
      </p>
      <blockquote>
        <p>
          <strong>Note:</strong> This scenario uses a biomedical lab as an example;
          EngramR works with any research domain.
        </p>
      </blockquote>

      <hr />

      <p>
        Two capabilities make this possible: a knowledge architecture that turns
        observations into a persistent graph of structured claims, and a co-scientist
        engine that generates, debates, and ranks testable predictions from that evidence.
        A knowledge graph without hypothesis generation is a well-organized archive; a
        hypothesis engine without structured evidence is speculation. The combination shifts
        the bottleneck from human attention to evidence quality.
      </p>

      <h2 id="a-morning">A morning</h2>

      <p>
        <strong>9:02am</strong> -- The tech notices something unexpected in her experiment.
        She sends a Slack message.
      </p>
      <blockquote>
        <p>"Seeing unexpected protein accumulation in the treated group at 24h. Wasn't
        part of the original hypothesis."</p>
      </blockquote>
      <p>She goes back to her bench.</p>

      <p>
        <strong>9:03am</strong> -- The reactor extracts a structured claim, tags it, and
        searches the knowledge graph. Three connections surface: a grad student's dataset
        from March that showed the same pattern, a paper the postdoc read last week about
        a related mechanism, and an existing hypothesis that predicted this involvement --
        but through a different mechanism. A tension is flagged.
      </p>

      <p>
        <strong>9:40am</strong> -- The postdoc gets a Slack notification: a new observation
        was linked to a literature note he submitted last week. He did not know anyone in
        the lab was generating data in this area.
      </p>
      <blockquote>
        <p>"Her data fits the alternative pathway better. If that's the mechanism, we
        should see it in the longitudinal dataset we already have."</p>
      </blockquote>

      <p>
        <strong>9:45am</strong> -- Evidence density crosses the threshold. The system
        generates an evolved hypothesis -- same core prediction, updated mechanism. It
        comes with a pre-specified analysis plan and statistical tests.
      </p>

      <p>
        <strong>10:00am</strong> -- The evolved hypothesis enters the tournament and
        debates the original head-to-head on specificity, evidence support, and testability.
        It wins -- three independent data sources where the original had one. Elo updates.
        Debate transcript stored.
      </p>

      <p>
        <strong>11:15am</strong> -- The postdoc executes the analysis. The hypothesis note
        contains the test, the parameters, and suggested experiments. Results: two of three
        predictions confirmed. One inconclusive. The system logs the experiment and flags
        the gap.
      </p>

      <p>
        <strong>11:30am</strong> -- The graph updates. The hypothesis holds its rank but
        carries a documented weakness. Next round, that weakness is fair game.
      </p>

      <h2 id="an-anomaly">An anomaly</h2>

      <p>
        A grad student uploads her dataset for exploratory analysis. The system generates
        a report -- plots in the lab's standard style, summary statistics, all processed
        locally. One finding stands out: a pattern in her data that does not match any
        existing hypothesis in the graph.
      </p>
      <p>She asks: "What could explain this?"</p>
      <p>
        The reactor searches the knowledge graph. It finds six related claims from
        literature and prior observations, identifies two possible mechanisms, and
        generates a hypothesis from the anomaly -- complete with predictions, a validation
        plan using data already on the server, and falsification criteria. The hypothesis
        enters the tournament that week.
      </p>
      <p>
        The anomaly that would have been a footnote in her thesis is now a ranked project
        proposal with structured evidence behind it.
      </p>

      <h2 id="administration">Administration</h2>

      <p>
        <strong>Writing aims from evidence.</strong> The PI needs specific aims for a new
        grant. She defines a research goal in the reactor. Six hypotheses generate from the
        existing graph. A tournament runs to rank them. Three survive -- each with
        mechanism, predictions, and preliminary data already identified from the lab's own
        datasets. The debate transcripts document why these beat the alternatives.
      </p>
      <p>
        <strong>Allocating resources.</strong> The lab has a slot for a new project. The PI
        filters the leaderboard by hypotheses testable with existing data. Three candidates
        surface with different cost profiles. The decision takes minutes. The evidence trail
        is there for anyone to review.
      </p>
      <p>
        <strong>New direction.</strong> The PI reads a paper that opens unexplored territory.
        She defines a new goal. The graph already has twelve relevant claims and two projects
        with transferable data. Three seed hypotheses generate from what the lab already
        knows. The new direction starts with context, not from zero.
      </p>

      <h2 id="across-labs">Across labs</h2>

      <p>One reactor per lab is valuable. Multiple reactors compound.</p>
      <p>
        Two labs in adjacent areas each run their own instance, generating and ranking
        hypotheses against their own data. The knowledge graphs bridge selectively -- Lab
        A's methodological observation connects to Lab B's independent finding from a
        different dataset. Neither lab would have seen it alone.
      </p>
      <p>
        This inverts the traditional collaboration model. Instead of two PIs deciding to
        collaborate and then looking for scientific overlap, the system surfaces the overlap
        first. The PIs decide whether to cross the bridge.
      </p>

      <hr />

      <p class="text-text-muted italic">
        The reactor is running. The question is which ideas to put into it.
      </p>

      <div class="mt-12 flex flex-col sm:flex-row gap-4">
        <a
          href={`${base}docs/getting-started/`}
          class="btn-primary inline-flex items-center justify-center"
        >
          Get started
        </a>
        <a
          href="https://github.com/achousal/EngramR"
          class="btn-secondary inline-flex items-center justify-center"
        >
          View on GitHub
        </a>
      </div>
    </article>
  </div>
</Base>
